{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3866e619-b4fa-4f59-83be-829e57c9b994",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import random\n",
    "import csv\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import json\n",
    "from esm.models.esmc import ESMC\n",
    "from esm.sdk.api import ESMProtein, LogitsConfig\n",
    "from sklearn.model_selection import train_test_split\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ef2151a-5f6e-4231-bd6d-fcf49fe663df",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_of_model = 'Name'\n",
    "blocks_unfrozen = 1\n",
    "base_block_lr = 0.001\n",
    "regression_block_lr = 0.01\n",
    "HLA = 'HLAA0201'\n",
    "encoding = 'epitope'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e1539a4-5ce9-4a4e-8b77-7a311eddf25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a90093de-b9a8-4673-bbc3-567d89032ca3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pretrained ESM_Cambrian model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "328ab836b28f476dbf3aba5e04074658",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 4 files:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "#########################################################\n",
    "# Model Definition: ESMCMasked\n",
    "#########################################################\n",
    "class ESMCMasked(nn.Module):\n",
    "    \"\"\"\n",
    "    A wrapper that takes a pre-trained ESM C model and adds\n",
    "    a masking (language modeling) head on top of the final hidden states.\n",
    "    This version expects batched input_ids and attention_mask in forward.\n",
    "    \"\"\"\n",
    "    def __init__(self, base_model, hidden_dim=960, num_aa=33):\n",
    "        super().__init__()\n",
    "        self.base_model = base_model  # Pretrained ESM C model\n",
    "        self.mask_head = nn.Linear(hidden_dim, num_aa)  # Simple linear LM head\n",
    "\n",
    "    def forward(self, input_ids, attention_mask=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "          input_ids: [batch_size, seq_len] integer tokens\n",
    "          attention_mask: [batch_size, seq_len], 1 for real tokens, 0 for padding\n",
    "        Returns:\n",
    "          out_logits: [batch_size, seq_len, num_aa]\n",
    "        \"\"\"\n",
    "        # 1) ESM forward\n",
    "        #    If your ESM model supports input_ids directly (like a HuggingFace model),\n",
    "        #    do something like:\n",
    "        outputs = self.base_model.forward(input_ids )\n",
    "        # outputs.hidden_states[-1]: [batch_size, seq_len, hidden_dim]\n",
    "        hidden_states = outputs.hidden_states[-1].to(torch.float32) # ensure float32\n",
    "\n",
    "        # 2) Pass through the custom LM head\n",
    "        out_logits = self.mask_head(hidden_states)  # [batch_size, seq_len, num_aa]\n",
    "        return out_logits\n",
    "\n",
    "##################################################\n",
    "# 3. Load the base ESM C model and wrap it\n",
    "##################################################\n",
    "print(\"Loading pretrained ESM_Cambrian model...\", flush = True)\n",
    "base_model = ESMC.from_pretrained(\"esmc_300m\").to(device)\n",
    "\n",
    "# Create our extended masked model\n",
    "model_masked = ESMCMasked(base_model, hidden_dim=960, num_aa=33).to(device)\n",
    "\n",
    "def load_model(model_path, device='cpu'):\n",
    "    # Load checkpoint\n",
    "    checkpoint = torch.load(model_path, map_location=device)\n",
    "    config = checkpoint['config']\n",
    "    \n",
    "    # 1. Load base ESMC model\n",
    "    base_model = ESMC.from_pretrained(\"esmc_300m\").to(device)\n",
    "    \n",
    "    # 3. Wrap with ESMCMasked using saved config\n",
    "    model = ESMBA(\n",
    "        base_model,\n",
    "    ).to(device)\n",
    "    \n",
    "    # 4. Load trained weights\n",
    "    state_dict = checkpoint['model_state_dict']\n",
    "\n",
    "    # Remove keys corresponding to the old mask head\n",
    "    state_dict = {k: v for k, v in state_dict.items()}\n",
    "    \n",
    "    model.load_state_dict(state_dict, strict=False)\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "# if not torch.cuda.is_available():\n",
    "#     print(\"CUDA is not available. Exiting.\")\n",
    "#     sys.exit(1)\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "print(f\"Using device: {device}\", flush=True)\n",
    "\n",
    "full_pretraining = False  # Simplified boolean conversion\n",
    "name_of_model = \"RUN2\"\n",
    "encoding = 'epitope'\n",
    "# file_path = '/global/scratch/users/sergiomar10/models/esm_c/masking/HLA-0201_epitope_only/False-Full_pretraining_2000_seq_AUG_3.pt'\n",
    "file_path = '/global/scratch/users/sergiomar10/models/esm_c/masking/ALLHLAs_epitope_only/False-Full_pretraining_100000_seq_AUG_3_ALL_HLAS.pt'\n",
    "\n",
    "# model = load_model(\n",
    "#     file_path,  # Must match training setting!\n",
    "#     device=device\n",
    "# )\n",
    "\n",
    "# base_model = model.base_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1f9fc3e-b9ff-47da-a9bc-ee2756febabc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered 6576 sequences for training.\n",
      "Data split: 5260 train, 658 val, 658 eval.\n",
      "After augmentation: 5260 training sequences.\n",
      "Data split: 5260 train, 658 val, 658 eval.\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "num_augmentations = 1\n",
    "\n",
    "#########################################################\n",
    "# FASTA Parser\n",
    "#########################################################\n",
    "def parse_fasta(file_path):\n",
    "    sequences = []\n",
    "    with open(file_path, 'r') as f:\n",
    "        header = None\n",
    "        seq = \"\"\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if line.startswith(\">\"):\n",
    "                if seq:\n",
    "                    sequences.append((header, seq))\n",
    "                    seq = \"\"\n",
    "                header = line[1:]\n",
    "            else:\n",
    "                seq += line\n",
    "        if seq:\n",
    "            sequences.append((header, seq))\n",
    "    return sequences\n",
    "\n",
    "#########################################################\n",
    "# Load + Filter Data\n",
    "#########################################################\n",
    "train_fasta_path = \"/global/scratch/users/sergiomar10/jupyter_notebooks/hla_protein_sequences.fasta\"\n",
    "all_data = parse_fasta(train_fasta_path)\n",
    "\n",
    "hla_and_epitopes = []\n",
    "for head, hla_seq in all_data:\n",
    "    # Parse out the HLA naming from header\n",
    "    head = head.split('|')[1][:7].replace('*', '').replace(':', '')\n",
    "    head = 'HLA' + head\n",
    "    if head != HLA:\n",
    "        continue\n",
    "\n",
    "    # Load the CSV for that HLA\n",
    "    iedb_path = f\"/global/scratch/users/sergiomar10/data/IEDB_SQL/IEDB_{head}_final.csv\"\n",
    "    df = pd.read_csv(iedb_path, header=None)\n",
    "    df.columns = [\n",
    "        'sequence', 'ref_ID', 'submissionID', 'Epitope_ID', 'protein_origin',\n",
    "        'ID_SOURCE', \"SOURCE_ORGANISM\", \"IC50_nM\", \"DESCRIPTION_BINDING\", \"Year_submission\"\n",
    "    ]\n",
    "    # Filter to \"Positive\" sequences\n",
    "    df = df[df['DESCRIPTION_BINDING'].str.contains(\"Positive\")][[\"ref_ID\",\"sequence\"]].values\n",
    "\n",
    "    for ref_id, epitope in df:\n",
    "        if any(x in epitope for x in ['+', '(', 'X']):\n",
    "            continue\n",
    "        # If your encoding mode = 'HLA', prepend the HLA sequence to epitope\n",
    "        if encoding == 'HLA':\n",
    "            epitope = hla_seq + epitope\n",
    "\n",
    "        hla_and_epitopes.append(epitope)\n",
    "\n",
    "hla_and_epitopes = np.unique(hla_and_epitopes)\n",
    "\n",
    "max_length = np.max([len(x) for x in hla_and_epitopes])\n",
    "\n",
    "random.shuffle(hla_and_epitopes)\n",
    "print(f\"Filtered {len(hla_and_epitopes)} sequences for training.\", flush=True)\n",
    "\n",
    "train_seqs, temp_seqs = train_test_split(hla_and_epitopes, test_size=0.2, random_state=42)\n",
    "val_seqs, eval_seqs = train_test_split(temp_seqs, test_size=0.5, random_state=42)\n",
    "\n",
    "print(f\"Data split: {len(train_seqs)} train, {len(val_seqs)} val, {len(eval_seqs)} eval.\", flush=True)\n",
    "\n",
    "# Now, apply augmentation only to the training set\n",
    "augmented_train_seqs = []\n",
    "for seq in train_seqs:\n",
    "    for _ in range(num_augmentations):\n",
    "        augmented_train_seqs.append(seq)\n",
    "\n",
    "print(f\"After augmentation: {len(augmented_train_seqs)} training sequences.\", flush=True)\n",
    "\n",
    "\n",
    "print(\n",
    "    f\"Data split: {len(train_seqs)} train, \"\n",
    "    f\"{len(val_seqs)} val, {len(eval_seqs)} eval.\",\n",
    "    flush=True\n",
    ")\n",
    "\n",
    "#########################################################\n",
    "# Masked LM Dataset\n",
    "#########################################################\n",
    "class MaskedProteinDataset(Dataset):\n",
    "    def __init__(self, sequences, base_model, mlm_probability=0.15, max_length=15):\n",
    "        self.sequences = sequences\n",
    "        self.tokenizer = base_model.tokenizer\n",
    "        self.mlm_probability = mlm_probability\n",
    "        self.max_length = max_length\n",
    "        self.pad_id = self.tokenizer.pad_token_id  # e.g. 1\n",
    "        self.mask_id = self.tokenizer.mask_token_id  # e.g. 32\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        seq = self.sequences[idx]\n",
    "        # 1) Tokenize the entire sequence up to self.max_length\n",
    "        encoding = self.tokenizer(\n",
    "            seq,\n",
    "            return_tensors='pt',\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            max_length=self.max_length\n",
    "        )\n",
    "        input_ids = encoding['input_ids'].squeeze(0)        # shape [seq_len]\n",
    "        attention_mask = encoding['attention_mask'].squeeze(0)  # shape [seq_len]\n",
    "\n",
    "        # 2) Mask only the last 11 real tokens\n",
    "        masked_input_ids, labels = self.mask_tokens(input_ids)\n",
    "\n",
    "        # Return everything, along with the raw sequence if needed\n",
    "        return masked_input_ids, attention_mask, labels, seq\n",
    "\n",
    "    def mask_tokens(self, input_ids):\n",
    "        \"\"\"\n",
    "        Masks tokens ONLY within the last 11 real (non-pad) positions.\n",
    "        All other positions remain unmasked.\n",
    "        \"\"\"\n",
    "        # Initialize labels to pad_id (which we'll ignore in the loss)\n",
    "        labels = torch.full_like(input_ids, self.pad_id)\n",
    "\n",
    "        # Identify all non-pad token positions\n",
    "        nonpad_positions = (input_ids != self.pad_id).nonzero(as_tuple=True)[0]\n",
    "        if len(nonpad_positions) == 0:\n",
    "            # Edge case: if there's nothing but padding, just return as-is\n",
    "            return input_ids, labels\n",
    "\n",
    "        # We'll only allow masking within the last 11 real tokens\n",
    "        # e.g., if we have 15 real tokens, we choose positions [-11:].\n",
    "        # if we have fewer than 11 real tokens, then it's effectively \"mask up to length\"\n",
    "        maskable_positions = nonpad_positions[-11:]  # slice last 11 indices\n",
    "\n",
    "        # Create a probability vector of 0 for all tokens, except for these last 11 real ones\n",
    "        probs = torch.zeros_like(input_ids, dtype=torch.float)\n",
    "        probs[maskable_positions] = self.mlm_probability  # mlm_probability only for last 11\n",
    "\n",
    "        # Decide which of those positions to actually mask\n",
    "        masked_indices = torch.bernoulli(probs).bool()\n",
    "\n",
    "        # Copy the original token IDs into 'labels' only where we do mask\n",
    "        labels[masked_indices] = input_ids[masked_indices]\n",
    "        # Replace masked positions in input_ids with <mask> \n",
    "        input_ids[masked_indices] = self.mask_id\n",
    "\n",
    "        return input_ids, labels\n",
    "\n",
    "\n",
    "def collate_fn(batch):\n",
    "    \"\"\"\n",
    "    batch is a list of tuples:\n",
    "        (masked_input_ids, attention_mask, labels, raw_sequence)\n",
    "    \"\"\"\n",
    "    input_ids_list, attn_masks_list, labels_list, raw_seqs_list = zip(*batch)\n",
    "\n",
    "    input_ids = torch.stack(input_ids_list, dim=0)\n",
    "    attention_mask = torch.stack(attn_masks_list, dim=0)\n",
    "    labels = torch.stack(labels_list, dim=0)\n",
    "\n",
    "    # raw_seqs_list is a tuple of strings (the raw epitopes), so just keep it as a list\n",
    "    return input_ids, attention_mask, labels, list(raw_seqs_list)\n",
    "\n",
    "\n",
    "def get_mlm_dataloader(sequences, base_model, batch_size=8, shuffle=True, max_length=15):\n",
    "    dataset = MaskedProteinDataset(\n",
    "        sequences,\n",
    "        base_model,\n",
    "        mlm_probability=0.15,\n",
    "        max_length=max_length\n",
    "    )\n",
    "    loader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        collate_fn=collate_fn\n",
    "    )\n",
    "    return loader\n",
    "\n",
    "#########################################################\n",
    "# Create DataLoaders\n",
    "#########################################################\n",
    "\n",
    "base_model = model_masked.base_model\n",
    "\n",
    "batch_size = 8\n",
    "train_loader = get_mlm_dataloader(train_seqs, base_model, batch_size=batch_size, shuffle=True, max_length=max_length)\n",
    "val_loader   = get_mlm_dataloader(val_seqs,   base_model, batch_size=batch_size, shuffle=False, max_length=max_length)\n",
    "eval_loader  = get_mlm_dataloader(eval_seqs,  base_model, batch_size=batch_size, shuffle=False, max_length=max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ff54fad-73de-46c9-8883-cd9b2ff33aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################\n",
    "# Training and Validation Loops\n",
    "#########################################################\n",
    "num_epochs = 10\n",
    "\n",
    "# Simple function to measure MLM accuracy on masked positions\n",
    "def evaluate_mlm_accuracy(loader):\n",
    "    \"\"\"Compute how often the model guesses the correct token for the masked tokens.\"\"\"\n",
    "    model_masked.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for input_ids, attention_mask, labels, _ in loader:\n",
    "            input_ids = input_ids.to(device)\n",
    "            attention_mask = attention_mask.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Forward\n",
    "            logits = base_model(input_ids, attention_mask)  # [batch_size, seq_len, vocab_size]\n",
    "            # We only compare at positions where labels != -100\n",
    "            mask_positions = (labels != 1)\n",
    "            if not mask_positions.any():\n",
    "                continue\n",
    "\n",
    "            # Predictions\n",
    "            preds = torch.argmax(logits, dim=-1)  # [batch_size, seq_len]\n",
    "            correct += (preds[mask_positions] == labels[mask_positions]).sum().item()\n",
    "            total += mask_positions.sum().item()\n",
    "\n",
    "    model_masked.train()\n",
    "    return correct / total if total > 0 else 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "069ba78b-761c-47e6-80fb-5a4e57b3ee06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "model_masked.eval()\n",
    "eval_results = []\n",
    "total_nll = 0.0\n",
    "total_tokens = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for input_ids, attention_mask, labels, raw_epitopes in eval_loader:\n",
    "        input_ids = input_ids.to(device)\n",
    "        attention_mask = attention_mask.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        logits = base_model(input_ids, attention_mask)\n",
    "        logits = logits.sequence_logits\n",
    "        \n",
    "        # Compute softmax probabilities and log probabilities\n",
    "        probs = F.softmax(logits, dim=-1)\n",
    "        log_probs = F.log_softmax(logits, dim=-1)\n",
    "        preds = torch.argmax(probs, dim=-1)\n",
    "\n",
    "        for b in range(input_ids.size(0)):\n",
    "            # Grab the actual epitope string for this sample\n",
    "            epitope_seq = raw_epitopes[b]\n",
    "\n",
    "            # Identify valid positions (for example, positions that are not padding; here, labels[b]!=1)\n",
    "            valid_positions = torch.where(labels[b] != 1)[0]\n",
    "            \n",
    "            for pos in valid_positions:\n",
    "                pos = pos.item()\n",
    "                original_id = labels[b, pos].item()\n",
    "                pred_id = preds[b, pos].item()\n",
    "                pred_prob = probs[b, pos, pred_id].item()\n",
    "\n",
    "                # Compute the negative log likelihood for this token and its perplexity\n",
    "                token_log_prob = log_probs[b, pos, original_id]\n",
    "                token_nll = -token_log_prob.item()\n",
    "                token_perplexity = math.exp(token_nll)\n",
    "\n",
    "                total_nll += token_nll\n",
    "                total_tokens += 1\n",
    "\n",
    "                original_aa = base_model.tokenizer.decode([original_id]).strip()\n",
    "                predicted_aa = base_model.tokenizer.decode([pred_id]).strip()\n",
    "\n",
    "                eval_results.append({\n",
    "                    \"batch_index\": b,\n",
    "                    \"epitope\": epitope_seq,\n",
    "                    \"position\": pos,\n",
    "                    \"original_aa\": original_aa,\n",
    "                    \"predicted_aa\": predicted_aa,\n",
    "                    \"predicted_prob\": pred_prob,\n",
    "                    \"token_perplexity\": token_perplexity  # Per-token perplexity\n",
    "                })\n",
    "\n",
    "# # Compute global perplexity over all valid tokens\n",
    "# if total_tokens > 0:\n",
    "#     avg_nll = total_nll / total_tokens\n",
    "#     global_perplexity = math.exp(avg_nll)\n",
    "# else:\n",
    "#     global_perplexity = float('inf')\n",
    "\n",
    "# print(f\"Global Perplexity: {global_perplexity:.4f}\")\n",
    "\n",
    "# # Save evaluation predictions to CSV\n",
    "# eval_df = pd.DataFrame(eval_results)\n",
    "# eval_save_dir = \"/global/scratch/users/sergiomar10/data/ESMC_Pretrain\"\n",
    "# os.makedirs(eval_save_dir, exist_ok=True)\n",
    "# eval_csv_path = os.path.join(eval_save_dir, f\"{name_of_model}.csv\")\n",
    "# eval_df.to_csv(eval_csv_path, index=False)\n",
    "# print(f\"Evaluation predictions saved to {eval_csv_path}\", flush=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ecfa5a3b-e698-4e22-a093-108b267aa3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df = pd.DataFrame(eval_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d08e53cd-6c7b-4123-9802-4eaa69eeae0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df['length'] = eval_df['epitope'].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bbc0efdd-d73f-458f-8b67-eb88197d4226",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>length</th>\n",
       "      <th>predicted_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>0.104474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>0.079255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>0.081328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>0.094776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12</td>\n",
       "      <td>0.087491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>16</td>\n",
       "      <td>0.099257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>20</td>\n",
       "      <td>0.103440</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   length  predicted_prob\n",
       "0       8        0.104474\n",
       "1       9        0.079255\n",
       "2      10        0.081328\n",
       "3      11        0.094776\n",
       "4      12        0.087491\n",
       "5      16        0.099257\n",
       "6      20        0.103440"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_df.loc[:, ['length', 'predicted_prob']].groupby('length').min().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "886e6a95-7a05-4400-bcb3-86f998235caa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({9: 780, 10: 317, 11: 10, 16: 5, 8: 5, 12: 2, 20: 1})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter(eval_df['length'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fe454ae4-c1f3-46ea-8147-568fe787180c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "np.log10(eval_df['token_perplexity']).hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f903e5-16b3-4dd6-b69f-b288e833578d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ESM_Cambrian",
   "language": "python",
   "name": "esm_cambrian"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
